{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Nile as a vector store with OpenAI\n",
    "\n",
    "This notebook will walk you through using Nile's Serverless Postgres as a vector store for embeddings generated by OpenAI. \n",
    "We'll show you how to:\n",
    "    - Create a database with a table to store your embeddings in Nile (using the built-in `pg_vector` extension)\n",
    "    - Load pre-computed embeddings, generated by OpenAI, to Nile\n",
    "    - Generate embeddings for a text query\n",
    "    - Search the stored embeddings with vector distance functions to find documents relevant to the text query\n",
    "\n",
    "## What is Nile?\n",
    "\n",
    "Nile is a Postgres platform specifically designed for AI-Native B2B companies, enabling to launch and scale quickly, securely, and in the most cost-effective manner.\n",
    "\n",
    "Nile's architecture provides the following key benefits:\n",
    "\n",
    "- Built-in tenant virtualization in Postgres for better data and vector embedding isolation.\n",
    "- Vector embedding store that is cost-effective and auto-scales to billions of embeddings across customers\n",
    "- Seamlessly autoscales as your customer's usage increases and scales to zero with no cold start time\n",
    "- User management built for multitenancy with user data stored in your Postgres database and unlimited active tenants and users.\n",
    "\n",
    "You can read more about Nile, its architecture and concepts in our [documentation](https://www.thenile.dev/docs/getting-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting this tutorial, you'll need to have the following:\n",
    "\n",
    "- Connection string to a Nile Postgres database. You can create one by signing up to [Nile](https://console.thenile.dev). After you create a database, generate credentials and copy the connection string from \"Settings\" page.\n",
    "- OpenAI API Key. If you don't have an OpenAI API key, you can get one from [https://beta.openai.com/account/api-keys](https://beta.openai.com/account/api-keys).\n",
    "\n",
    "After you have both strings, set them as environment variables. Note that if you are running this notebook locally, you'll need to reload the terminal and the notebook to pick up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! export OPENAI_API_KEY=\"sk-xxxxxxxxxxxxxxxxxxxxx\"\n",
    "! export DATABASE_URL=postgres://nile:password@db.thenile.dev:5432/nile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements\n",
    "\n",
    "This notebook uses OpenAI's client to generate embeddings, and `psycopg2`, Python's popular Postgres client, to store and query the embeddings in Nile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! pip install openai psycopg2-binary pandas numpy wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "# Test that your OpenAI API key is correctly set as an environment variable\n",
    "# Note. if you run this notebook locally, you will need to reload your terminal and the notebook for the env variables to be live.\n",
    "import os\n",
    "\n",
    "# Note. alternatively you can set a temporary env variable like this:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Nile\n",
    "\n",
    "We start by connecting to our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfull connection\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "## If you are running this notebook locally, you will need to set the DATABASE_URL env variable, or set it here directly:\n",
    "# os.environ[\"DATABASE_URL\"] = \"postgres://user:password@db.thenile.dev:5432/nile\"\n",
    "\n",
    "connection = psycopg2.connect(os.getenv(\"DATABASE_URL\"))\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT 'successfull connection';\")\n",
    "print(cursor.fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings\n",
    "\n",
    "We'll use a file with pre-generated embeddings of wikipedia articles prepared with OpenAI's `text-embedding-ada-002` model. By using prepared embeddings, we'll save on the cost of generating the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "# the embedding file is 700MB, so it may take a while to download\n",
    "embeddings_url = \"https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip\"\n",
    "wget.download(embeddings_url)\n",
    "\n",
    "# unzip the file\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"vector_database_wikipedia_articles_embedded.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./data/\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table for embedding data\n",
    "\n",
    "We'll need a table to store the wikipedia articles and their embeddings. Nile has both tenant-aware tables, in which each row belongs to one customer, access controls are applied and they automatically scales out as tenants are added, and shared tables, which every tenant can access. Both types of tables can have `vector` columns for embeddings. \n",
    "\n",
    "In this example, we'll create a tenant called `Simple Wiki` and store the data in a tenant-aware table. This model will let us load additional data from other Wikis in the future and isolate them to their own tenants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "connection = psycopg2.connect(os.getenv(\"DATABASE_URL\"))\n",
    "cursor = connection.cursor()\n",
    "# create tenant\n",
    "cursor.execute(\"INSERT INTO tenants (name) VALUES ('Simple Wiki') RETURNING id;\")\n",
    "tenant_id = cursor.fetchone()[0]\n",
    "\n",
    "# create the table\n",
    "cursor.execute(f\"\"\"\n",
    "               CREATE TABLE articles (\n",
    "                   tenant_id UUID NOT NULL, -- this makes the table tenant-aware\n",
    "                   id integer,\n",
    "                   url TEXT,\n",
    "                   title TEXT,\n",
    "                   content TEXT,\n",
    "                   title_vector VECTOR(1536),\n",
    "                   content_vector VECTOR(1536),\n",
    "                   vector_id INTEGER,\n",
    "                  PRIMARY KEY (tenant_id, id)\n",
    "               );\"\"\")\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data to database\n",
    "\n",
    "Next, we'll use batch inserts to load the data to the table. First, we'll load the data into a Pandas data frame and from there's we'll insert it to the table.\n",
    "We are using a transaction\n",
    "This will take a few minutes, so a good time to grab coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 1000 rows\n",
      "Inserted 2000 rows\n",
      "Inserted 3000 rows\n",
      "Inserted 4000 rows\n",
      "Inserted 5000 rows\n",
      "Inserted 6000 rows\n",
      "Inserted 7000 rows\n",
      "Inserted 8000 rows\n",
      "Inserted 9000 rows\n",
      "Inserted 10000 rows\n",
      "Inserted 11000 rows\n",
      "Inserted 12000 rows\n",
      "Inserted 13000 rows\n",
      "Inserted 14000 rows\n",
      "Inserted 15000 rows\n",
      "Inserted 16000 rows\n",
      "Inserted 17000 rows\n",
      "Inserted 18000 rows\n",
      "Inserted 19000 rows\n",
      "Inserted 20000 rows\n",
      "Inserted 21000 rows\n",
      "Inserted 22000 rows\n",
      "Inserted 23000 rows\n",
      "Inserted 24000 rows\n",
      "Inserted 25000 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv(\"data/vector_database_wikipedia_articles_embedded.csv\")\n",
    "data[\"tenant_id\"] = tenant_id # add column with tenant_id of the tenant we created\n",
    "data = data.rename(columns={'text': 'content'}) # rename column to match the table\n",
    "\n",
    "# insert the data in batches\n",
    "batch_size = 1000\n",
    "connection = psycopg2.connect(os.getenv(\"DATABASE_URL\"))\n",
    "cursor = connection.cursor()\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data.iloc[i:i+batch_size]\n",
    "    cols = ','.join(list(data.columns))\n",
    "    tuples = [tuple(x) for x in batch.to_numpy()] \n",
    "    query = \"INSERT INTO articles(%s) VALUES %%s\" % (cols)\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        print(f\"Inserted {i + len(batch)} rows\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        connection.rollback()\n",
    "        break\n",
    "# commit after all inserts are done\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a vector index\n",
    "\n",
    "In order to speed up the search, we'll build a vector index on the embeddings. We'll use the `pg_vector` extension to create a vector index on both the `title_vector` and `content_vector` columns. `pg_vector` supports both HNSW and IVFFlat indices, each can be tuned with different parameters. \n",
    "\n",
    "We'll create an index on the `title_vector` column with IVFFlat index. It is smaller and faster to build than HNSW, but it does trade off some search performance and accuracy. As we'll see below, this works well for this dataset. Pg_vector documentation recommends setting the `lists` parameter to  `number of rows / 1000` when used with data sets below 1M rows, so we follow that recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(os.getenv(\"DATABASE_URL\"))\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"CREATE INDEX ON articles USING ivfflat (title_vector vector_cosine_ops) WITH (lists = 25);\")\n",
    "cursor.execute(\"CREATE INDEX ON articles USING ivfflat (content_vector vector_cosine_ops) WITH (lists = 25);\")\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the data\n",
    "\n",
    "Now that we have the documents and embeddings, we can use this to search for wikipedia articles relevant to a topic. This is the fun part!\n",
    "\n",
    "We'll start by defining a function that given a text query will find top-N relevant documents. It starts by generating an embedding for the query using OpenAI. Since the embeddings were generated with `text-embedding-ada-002` model, we must use the same model for searching. \n",
    "Then it we'll use SQL to find near-by vectors in the database. We'll use the familiar cosine distance method from `pg_vector`.\n",
    "\n",
    "Since the dataset has two embeddings - one for the title and one for the content of the articles, we'll also have a column_name parameter, which will let us choose which embedding to search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from psycopg2 import sql\n",
    "\n",
    "def find_similar_articles(query, vector_name, top_n=10):\n",
    "    # get the vector for the query\n",
    "    embedded_query = openai.embeddings.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    ).data[0].embedding\n",
    "    \n",
    "    formatted_embedding = \"'[\" + \",\".join(map(str, embedded_query)) + \"]'\"\n",
    "    # Connect to the virtual tenant database\n",
    "    connection = psycopg2.connect(os.environ['DATABASE_URL'])\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute('set nile.tenant_id = %s', (tenant_id,))\n",
    "    \n",
    "    sql_query = sql.SQL(\n",
    "          \"\"\"SELECT id, title, {vector_name} <=> {embedded_query}::VECTOR(1536) as cosine_distance \n",
    "            -- if you want to try another distance: embedding <-> $2 as euclidean_distance, (embedding <#> $2)* -1 as inner_product\n",
    "            FROM articles\n",
    "            ORDER BY ({vector_name} <=>  {embedded_query})\n",
    "            LIMIT ({top_n});\"\"\")\n",
    "\n",
    "    # find the most similar articles\n",
    "    try:\n",
    "        cursor.execute(sql_query.format(\n",
    "            vector_name=sql.Identifier(vector_name),\n",
    "            embedded_query=sql.SQL(formatted_embedding),\n",
    "            top_n=sql.Literal(top_n)))\n",
    "        return cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        connection.rollback()\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this method, we can start querying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Albert Einstein (Score: 0.0)\n",
      "2. Alan Turing (Score: 0.114)\n",
      "3. Isaac Newton (Score: 0.119)\n",
      "4. J. Robert Oppenheimer (Score: 0.121)\n",
      "5. Nikola Tesla (Score: 0.122)\n",
      "6. Carl Friedrich Gauss (Score: 0.122)\n",
      "7. Einsteinium (Score: 0.124)\n",
      "8. Leonhard Euler (Score: 0.125)\n",
      "9. Einstein on the Beach (Score: 0.125)\n",
      "10. Bertrand Russell (Score: 0.127)\n"
     ]
    }
   ],
   "source": [
    "query_results = find_similar_articles(\"Albert Einstein\", \"title_vector\")\n",
    "for i, article in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {article[1]} (Score: {round(float(article[2]), 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Albert Einstein (Score: 0.112)\n",
      "2. Hermann Minkowski (Score: 0.148)\n",
      "3. Theory of relativity (Score: 0.154)\n",
      "4. General relativity (Score: 0.163)\n",
      "5. Erwin Schrödinger (Score: 0.164)\n",
      "6. Physicist (Score: 0.164)\n",
      "7. Arnold Sommerfeld (Score: 0.165)\n",
      "8. List of physicists (Score: 0.166)\n",
      "9. J. Robert Oppenheimer (Score: 0.167)\n",
      "10. 1921 (Score: 0.168)\n"
     ]
    }
   ],
   "source": [
    "query_results = find_similar_articles(\"Albert Einstein\", \"content_vector\")\n",
    "for i, article in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {article[1]} (Score: {round(float(article[2]), 3)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
